{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "import string\n",
    "import re as regexz\n",
    "import random\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "from htmldate import find_date\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "import threading\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "from urllib.error import HTTPError, URLError\n",
    "from http.client import IncompleteRead\n",
    "\n",
    "base_path = os.getcwd()\n",
    "source_image_folder = \"C://Users//Ruben//Documents//GitHub//ReACT_GCV//code//work//environment2//ks_source\"\n",
    "image_folder_base = \"image_ks_\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadJson(filename):\n",
    "    with open(filename) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        return data\n",
    "def getImageURL(json_object):\n",
    "    list_url = []\n",
    "\n",
    "    for c,i in enumerate(json_object['responses'][0]['webDetection']['pagesWithMatchingImages']):\n",
    "        if 'partialMatchingImages' in i.keys():\n",
    "\n",
    "            for c2,x in enumerate(i['partialMatchingImages']):\n",
    "                for u in list(dict(x).values()):\n",
    "                    list_url.append(u)\n",
    "\n",
    "        elif 'fullMatchingImages' in i.keys():\n",
    "\n",
    "            for c2,x in enumerate(i['fullMatchingImages']):\n",
    "                for u in list(dict(x).values()):\n",
    "                    list_url.append(u)\n",
    "    return list_url\n",
    "\n",
    "def scraperOne(url,savepath):\n",
    "    global THREAD_COUNTER\n",
    "    THREAD_COUNTER += 1\n",
    "    \n",
    "    fn = savepath\n",
    "    if \"png\" in url:\n",
    "        fn = str(fn) + \".png\"\n",
    "    elif \"jpg\" in url:\n",
    "        fn = str(fn) + \".jpg\"\n",
    "    elif \"Jpeg\" in url:\n",
    "        fn = str(fn) + \".jpg\"\n",
    "    elif \"jpeg\" in url:\n",
    "        fn = str(fn) + \".jpg\"\n",
    "    elif \"JPG\" in url:\n",
    "        fn = str(fn) + \".jpg\"\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, fn)\n",
    "        print(fn, url)\n",
    "    except (HTTPError, URLError, TimeoutError,IncompleteRead) as e:\n",
    "        return\n",
    "    THREAD_COUNTER -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_image_folder = image_folder_base + str(2)\n",
    "list_json = [f for f in os.listdir(os.path.join(base_path, 'environment2' ,current_image_folder)) if '.json' in f]\n",
    "\n",
    "all_url = []\n",
    "for js in list_json:\n",
    "    json_data = loadJson(os.path.join(base_path, 'environment2' ,current_image_folder,js))\n",
    "\n",
    "    try:\n",
    "        temp_url = getImageURL(json_data)\n",
    "        all_url = all_url + temp_url\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "all_url = list(set(all_url))[0:10]\n",
    "#all_url = [(i,c) for c,i in enumerate(all_url)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.jpg http://g.udn.com.tw/upfiles/B_LW/lwv2013/PSN_PHOTO/698/f_23172698_1.jpg\n",
      "5.jpg https://2.bp.blogspot.com/-HTsjJRsTAMA/WHf_U9v0A4I/AAAAAAAAGP4/Q3WYM8i_yHMM1di-F8Z741G-OWcTwI7pwCLcB/s1600/Top%2B100%2BOf%2BThe%2BMost%2BInfluential%2BPhotos%2BOf%2BAll%2BTime%2B-%2BKent%2BState%2BShootings%252C%2BJohn%2BPaul%2BFilo%252C%2B1970.jpg\n",
      "6.jpg https://images.squarespace-cdn.com/content/v1/53bc0878e4b0f9fe5b575998/1494624771908-92TNBMEJFA2YGALHXS7N/ke17ZwdGBToddI8pDm48kAnnfea7JZz1tZW0EpnfudJ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UYr145E5OlY98cRAWWqRCZ8n80TzcSqjVZW-hRqTdSE10sc8M5GEoqn2Jm2XhV6veQ/time-100-influential-photos-john-paul-filo-kent-state-shootings-65.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-417a010e403a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0m_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mwhile\u001b[0m \u001b[0mTHREAD_COUNTER\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mTHREAD_MAX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "THREAD_COUNTER = 0\n",
    "THREAD_MAX     = 5\n",
    "\n",
    "for c,url in enumerate(all_url):\n",
    "    fn = os.path.join(base_path, 'environment2' ,current_image_folder,'img',str(c)) \n",
    "    _t = threading.Thread(target=scraperOne, args=(url,fn) )\n",
    "    _t.daemon = True\n",
    "    _t.start()\n",
    "\n",
    "    while THREAD_COUNTER >= THREAD_MAX:\n",
    "        pass\n",
    "\n",
    "while THREAD_COUNTER > 0:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Ruben\\\\Documents\\\\GitHub\\\\ReACT_GCV\\\\code\\\\work'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
