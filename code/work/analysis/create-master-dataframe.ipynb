{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from random import sample\n",
    "from htmldate import find_date\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "from langid.langid import LanguageIdentifier, model\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"page_id\",\"page_url\",\"image_url\",\"date\",\"language\",\"topleveldomain\",\"category\",\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e7207dc156db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdates_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mphoto\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mphoto_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphoto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"dates.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'base_path' is not defined"
     ]
    }
   ],
   "source": [
    "# Load Date Dictionary\n",
    "dates_ref = dict()\n",
    "\n",
    "for photo in [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]:\n",
    "    photo_folder = os.path.join(base_path, photo)\n",
    "    with open(os.path.join(photo_folder,\"dates.txt\"),'r') as f:\n",
    "        x = f.readlines()\n",
    "    dates_ref.update({d.split('|')[0]:d.split('|')[-1].replace('\\n','') for d in x if d.split('|')[-1].replace('\\n','') != \"na\" and \"ERROR\" not in d.split('|')[-1].replace('\\n','')})\n",
    "\n",
    "# Load Language Dictionary\n",
    "d_ = []\n",
    "for photo in [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]:\n",
    "    photo_folder = os.path.join(base_path, photo)\n",
    "    \n",
    "    with open(os.path.join(photo_folder,'languages-'+photo+\".json\"),'r') as f:\n",
    "        lang = json.load(f)\n",
    "    \n",
    "    languages = []\n",
    "    \n",
    "    for iterkey,items1 in lang.items():\n",
    "        \n",
    "        for id_, lan_items in items1.items():\n",
    "            \n",
    "            if id_ in dates_ref.keys():\n",
    "                date = dates_ref[id_]\n",
    "                language = lan_items[0]\n",
    "                \n",
    "                d_.append([photo,language,date[0:4],1])\n",
    "                \n",
    "# Load Text Dictionary\n",
    "dt = dict()\n",
    "\n",
    "for photo in [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]:\n",
    "    photo_folder = os.path.join(base_path, photo)\n",
    "    num_iterations = [fol for fol in os.listdir(photo_folder) if os.path.isdir(os.path.join(photo_folder,fol)) and \"source\" not in fol and \"context\" not in fol]\n",
    "    num_iterations = len(num_iterations)\n",
    "\n",
    "    start_iter = 1\n",
    "    range_iter = [str(i) for i in list(range(1,num_iterations + 1))]\n",
    "\n",
    "    folder_base = os.path.join(base_path,photo,photo)\n",
    "\n",
    "    for iteration in range_iter:\n",
    "        fn = os.path.join(folder_base + \"_\" +str(iteration),\"txt\", \"parsed_text.json\")\n",
    "        with open(fn) as fp:\n",
    "            pages = json.load(fp)\n",
    "            \n",
    "        for identifier,sentences in pages.items():\n",
    "            \n",
    "            sentences = [s.replace(\"\\n\",\"\").lower() for s in sentences]\n",
    "            sentences = [re.sub(' +', ' ', s) for s in sentences]\n",
    "\n",
    "            url = identifier.split('html_')[-1]\n",
    "            id_ = identifier.split('/html/')[1].split('.html_')[0]\n",
    "            if url in dates_ref.keys():\n",
    "                date = dates_ref[url]\n",
    "            else:\n",
    "                date = \"na\"\n",
    "            \n",
    "            language = langid.classify(\" \".join(sentences))[0]\n",
    "            if language not in dt.keys():\n",
    "                dt.update({language:dict()})\n",
    "            \n",
    "            dt[language].update({identifier:dict()})\n",
    "            dt[language][identifier].update({\"url\":url,\"identifier\":id_,\"date\":date,\"sentences\":sentences})\n",
    "            \n",
    "            \n",
    "# Define Category Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 ['11_1', '11_2', '11_3']\n",
      "12 ['12_1', '12_2', '12_3', '12_4']\n",
      "13 ['13_1', '13_2', '13_3', '13_4', '13_5']\n",
      "14 ['14_1', '14_2', '14_3', '14_4']\n",
      "16 ['16_1', '16_2', '16_3']\n",
      "17 ['17_1', '17_2']\n",
      "18 ['18_1', '18_2', '18_3']\n",
      "19 ['19_1', '19_2']\n",
      "2 ['2_1', '2_2', '2_3']\n",
      "21 ['21_1', '21_2', '21_3', '21_4', '21_5']\n",
      "22 ['22_1', '22_2', '22_3']\n",
      "24 ['24_1', '24_2', '24_3']\n",
      "25 ['25_1', '25_2', '25_3', '25_4']\n",
      "27 ['27_1', '27_2', '27_3', '27_4', '27_5']\n",
      "28 ['28_1', '28_2', '28_3', '28_4']\n",
      "3 ['3_1', '3_2', '3_3', '3_4', '3_5', '3_6']\n",
      "4 ['4_1', '4_2', '4_3']\n",
      "59 ['59_1', '59_2', '59_3']\n",
      "60 ['60_1', '60_2', '60_3', '60_4']\n",
      "63 ['63_1', '63_2', '63_3', '63_4']\n",
      "7 ['7_1', '7_2', '7_3', '7_4', '7_5', '7_6']\n",
      "8 ['8_1', '8_2', '8_3', '8_4']\n",
      "9 ['9_1', '9_2', '9_3', '9_4', '9_5', '9_6']\n"
     ]
    }
   ],
   "source": [
    "# Number of Webpages\n",
    "base_path = \"/media/ruben/Data Drive/react-data/protest/carlo-batch-selection\"\n",
    "\n",
    "\n",
    "for photo in [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]:\n",
    "    photo_folder = os.path.join(base_path, photo)\n",
    "\n",
    "    folders = [fol for fol in os.listdir(photo_folder) if os.path.isdir(os.path.join(photo_folder,fol)) and \"source\" not in fol and \"context\" not in fol]\n",
    "    print(photo, folders)\n",
    "    \n",
    "    for fol in folders:\n",
    "        htmls = [f for f in os.listdir(os.path.join(photo_folder,fol,\"html\")) if \".html\" in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Scrape-Images\n",
    "dt = dict()\n",
    "for photo in [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]:\n",
    "    photo_folder = os.path.join(base_path, photo)\n",
    "    dt.update({photo:0})\n",
    "\n",
    "    folders = [fol for fol in os.listdir(photo_folder) if os.path.isdir(os.path.join(photo_folder,fol)) and \"source\" not in fol and \"context\" not in fol]\n",
    "\n",
    "    for fol in folders[:-1]:\n",
    "        htmls = len([f for f in os.listdir(os.path.join(photo_folder,fol,\"img\")) if \".txt\" not in f])\n",
    "        if htmls == 0:\n",
    "            dt[photo] += 1\n",
    "        else:\n",
    "            dt[photo] += htmls\n",
    "            \n",
    "d2 = pd.DataFrame(dt.items(),columns = ['image','n_scrape-images'])\n",
    "d2 = d2.sort_values('image',ascending=False)\n",
    "d['n_scrape-images'] = d2['n_scrape-images'] + 1\n",
    "d['scrape-ratio'] = 1 - round(d['n_scrape-images'] / d['n_webpages'],2)\n",
    "d = d.sort_values('image',ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Text-Scraped Pages\n",
    "dt = dict()\n",
    "for photo in [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]:\n",
    "        photo_folder = os.path.join(base_path, photo)\n",
    "        dt.update({photo:0})\n",
    "        \n",
    "        folders = [fol for fol in os.listdir(photo_folder) if os.path.isdir(os.path.join(photo_folder,fol)) and \"source\" not in fol and \"context\" not in fol]\n",
    "        \n",
    "        for fol in folders:\n",
    "            text_jsons = [f for f in os.listdir(os.path.join(photo_folder,fol,\"txt\")) if \".json\" in f]\n",
    "            \n",
    "            for js in text_jsons:\n",
    "                fn = os.path.join(photo_folder,fol,\"txt\",js)\n",
    "                with open(fn,'r') as fp:\n",
    "                    js = json.load(fp)\n",
    "                    list_sentences = [v for k,v in js.items()]\n",
    "                    list_sentences = [len(item) for sublist in list_sentences for item in sublist]\n",
    "                    dt[photo] += sum(list_sentences)\n",
    "                    \n",
    "d3 = pd.DataFrame(dt.items(),columns = ['image','n_scraped-text-characters'])\n",
    "d3 = d3.sort_values('image',ascending=False)\n",
    "d['n_scraped-text-characters'] = d3['n_scraped-text-characters']\n",
    "d['char-page-ratio'] = round(d['n_scraped-text-characters'] / d['n_webpages'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/ruben/Data Drive/react-data/protest/carlo-batch-selection/11/context_images'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2737a226331a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mphoto\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mcimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"context_images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\".txt\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mdt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphoto\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/ruben/Data Drive/react-data/protest/carlo-batch-selection/11/context_images'"
     ]
    }
   ],
   "source": [
    "# Number of Context-Images\n",
    "\n",
    "dt = dict()\n",
    "for photo in [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]:\n",
    "        photo_folder = os.path.join(base_path, photo)\n",
    "        dt.update({photo:0})\n",
    "        \n",
    "        cimgs = [f for f in os.listdir(os.path.join(photo_folder,\"context_images\")) if \".txt\" not in f]\n",
    "        dt[photo] += len(cimgs)\n",
    "        \n",
    "d4 = pd.DataFrame(dt.items(),columns = ['image','n_context-images'])\n",
    "d4 = d4.sort_values('image',ascending=False)\n",
    "d['n_context-images'] = d4['n_context-images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Dates\n",
    "\n",
    "dt = dict()\n",
    "for photo in [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]:\n",
    "        photo_folder = os.path.join(base_path, photo)\n",
    "        dt.update({photo:0})\n",
    "        \n",
    "        with open(os.path.join(base_path,photo,\"dates.txt\"), 'r') as f:\n",
    "            dates = f.readlines()\n",
    "            dates = [d for d in dates if d.split('|')[1].replace('\\n','') != \"na\" and \"ERROR\" not in d.split('|')[1]]\n",
    "            dt[photo] += len(dates)\n",
    "d5 = pd.DataFrame(dt.items(),columns = ['image','n_dates'])\n",
    "d5 = d5.sort_values('image',ascending=False)\n",
    "d['n_dates'] = d5['n_dates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['image'] = d['image'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.sort_values('image',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "\n",
    "d.to_csv('/media/ruben/FEF44259F44213F5/Users/Ruben/Documents/GitHub/ReACT_GCV/data/images_tables_article_carlo/descriptive-full.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Languages\n",
    "\n",
    "dt = pd.DataFrame()\n",
    "\n",
    "for photo in [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]:\n",
    "    photo_folder = os.path.join(base_path, photo)\n",
    "    \n",
    "    with open(os.path.join(photo_folder,'languages-'+photo+\".json\"),'r') as f:\n",
    "        lang = json.load(f)\n",
    "        lang = lang['1']\n",
    "        lang = dict(Counter([v[0] for k,v in lang.items()]))\n",
    "        lang = pd.DataFrame(list(lang.items()))\n",
    "        lang['photo'] = photo\n",
    "    dt = dt.append(lang)\n",
    "dt.columns = ['lang','count','photo']\n",
    "d6 = dt.pivot(index=\"photo\",columns=\"lang\",values=\"count\").reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
